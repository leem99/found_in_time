{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create \"Model Topper\" using example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense,GlobalAveragePooling2D\n",
    "from keras import applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299\n",
    "n_features = 6\n",
    "\n",
    "top_model_weights_path = 'bottleneck_xception_model.h5'\n",
    "train_data_dir = 'multi_class_testing/train/'\n",
    "validation_data_dir = 'multi_class_testing/test/'\n",
    "\n",
    "available_train_files = len(os.listdir(train_data_dir + 'female/')) \\\n",
    "    + len(os.listdir(train_data_dir + 'male/'))\n",
    "available_test_files = len(os.listdir(validation_data_dir + 'female/')) \\\n",
    "    + len(os.listdir(validation_data_dir+'male/'))\n",
    "    \n",
    "nb_train_samples  = available_train_files - available_train_files % 8\n",
    "nb_validation_samples = available_test_files - available_test_files % 8\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Set up Multiclass Testing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_df = pd.read_csv('all_watch_info_with_indicators.csv')\n",
    "watch_dict = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace These Features with something better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image_name in watch_df['image_name']:\n",
    "    watch_dict[image_name+'.jpg'] =  watch_df[\n",
    "        watch_df['image_name'] == image_name][\n",
    "            ['is_gold','is_silver','is_strap','is_square','is_round','is_male']].values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiclass Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclasses_getter(x, i, gen):\n",
    "    count = 0\n",
    "    y = np.zeros((batch_size, n_features), dtype=np.int8)\n",
    "    \n",
    "    # Feature not working\n",
    "    if np.shape(x)[0] < gen.batch_size:\n",
    "        steps = np.shape(x)[0]\n",
    "    else:\n",
    "        steps = gen.batch_size\n",
    "        \n",
    "    idx = (i) * gen.batch_size\n",
    "    \n",
    "    for f in gen.filenames[idx : idx + steps]:\n",
    "        k = f.split('/')[-1]\n",
    "        y[count,:] = watch_dict[k] \n",
    "        count += 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclass_flow_train(flow_from_directory_gen, multiclasses_getter):\n",
    "    for i, (x, y) in enumerate(flow_from_directory_gen):\n",
    "        yield x, multiclasses_getter(x, i,train_generator)\n",
    "    \n",
    "def multiclass_flow_test(flow_from_directory_gen, multiclasses_getter):\n",
    "    for i, (x, y) in enumerate(flow_from_directory_gen):\n",
    "        yield x, multiclasses_getter(x, i, test_generator)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7336 images belonging to 2 classes.\n",
      "Found 3144 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Standard Xception Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.xception.Xception(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build My \"Custom\" Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Model)             (None, None, None, 2048)  20861480  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 20,873,774\n",
      "Trainable params: 20,819,246\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "watch_model = Sequential()\n",
    "watch_model.add(model)\n",
    "watch_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "watch_model.add(Dense(6, activation=\"sigmoid\"))\n",
    "watch_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze Exception Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in watch_model.layers[0].layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_model.compile(loss = \"binary_crossentropy\", optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "917/917 [==============================] - 452s - loss: 0.3797 - acc: 0.8196 - val_loss: 0.5285 - val_acc: 0.7938\n",
      "Epoch 2/2\n",
      "917/917 [==============================] - 449s - loss: 0.0843 - acc: 0.9774 - val_loss: 0.0200 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2400d9a0b8>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "watch_model.fit_generator(\n",
    "        multiclass_flow_train(train_generator, multiclasses_getter),\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data = multiclass_flow_test(test_generator, multiclasses_getter),\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_model.save('xception_multiclass1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
