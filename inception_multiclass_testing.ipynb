{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclassification InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from itertools import islice\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import cv2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras import applications\n",
    "\n",
    "from sklearn.metrics import jaccard_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dimensions of our images.\n",
    "img_width, img_height = 299, 299\n",
    "n_features = 6\n",
    "\n",
    "train_data_dir = 'multi_class_testing/train/'\n",
    "validation_data_dir = 'multi_class_testing/test/'\n",
    "\n",
    "available_train_files = len(os.listdir(train_data_dir + 'female/')) \\\n",
    "    + len(os.listdir(train_data_dir + 'male/'))\n",
    "available_test_files = len(os.listdir(validation_data_dir + 'female/')) \\\n",
    "    + len(os.listdir(validation_data_dir+'male/'))\n",
    "    \n",
    "nb_train_samples  = available_train_files - available_train_files % 8\n",
    "nb_validation_samples = available_test_files - available_test_files % 8\n",
    "\n",
    "\n",
    "epochs = 2\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_df = pd.read_csv('all_watch_info_with_indicators.csv')\n",
    "watch_dict = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image_name in watch_df['image_name']:\n",
    "    watch_dict[image_name+'.jpg'] =  watch_df[\n",
    "        watch_df['image_name'] == image_name][\n",
    "            ['is_gold','is_silver','is_strap','is_square','is_round','is_male']].values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Custom Generator and Helper Function__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiclasses_getter(x, i, gen):\n",
    "    count = 0\n",
    "    y = np.zeros((batch_size, n_features), dtype=np.int8)\n",
    "    \n",
    "    # Feature not working\n",
    "    if np.shape(x)[0] < gen.batch_size:\n",
    "        steps = np.shape(x)[0]\n",
    "    else:\n",
    "        steps = gen.batch_size\n",
    "        \n",
    "    idx = (i) * gen.batch_size\n",
    "    \n",
    "    for f in gen.filenames[idx : idx + steps]:\n",
    "        k = f.split('/')[-1]\n",
    "        y[count,:] = watch_dict[k] \n",
    "        count += 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def multiclass_flow_from_directory(flow_from_directory_gen, multiclasses_getter):\n",
    "#     for x, y in flow_from_directory_gen:\n",
    "#         yield x, multiclasses_getter(x, y)\n",
    "        \n",
    "def multiclass_flow_train(flow_from_directory_gen, multiclasses_getter):\n",
    "    for i, (x, y) in enumerate(flow_from_directory_gen):\n",
    "        yield x, multiclasses_getter(x, i,train_generator)\n",
    "    \n",
    "def multiclass_flow_test(flow_from_directory_gen, multiclasses_getter):\n",
    "    for i, (x, y) in enumerate(flow_from_directory_gen):\n",
    "        yield x, multiclasses_getter(x, i, test_generator)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7336 images belonging to 2 classes.\n",
      "Found 3144 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)\n",
    "\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height,img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watch_df[\n",
    "        watch_df['image_name'] == 'OmegaDeVillePrestigeCoAxial32742420332005002'][\n",
    "            ['is_gold','is_silver','is_strap','is_square','is_round','is_male']].values[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = applications.InceptionV3(include_top=True, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_name = 'mixed10'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_model = Sequential()\n",
    "watch_model.add(intermediate_layer_model)\n",
    "watch_model.add(GlobalAveragePooling2D(name='avg_pool'))\n",
    "watch_model.add(Dense(6, activation=\"sigmoid\"))\n",
    "\n",
    "watch_model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_model.compile(loss = \"binary_crossentropy\", optimizer='sgd', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_2 (Model)              (None, None, None, 2048)  21802784  \n",
      "_________________________________________________________________\n",
      "avg_pool (GlobalAveragePooli (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 12294     \n",
      "=================================================================\n",
      "Total params: 21,815,078\n",
      "Trainable params: 12,294\n",
      "Non-trainable params: 21,802,784\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "watch_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "917/917 [==============================] - 876s - loss: 0.1779 - acc: 0.9366 - val_loss: 0.3986 - val_acc: 0.9106\n",
      "Epoch 2/2\n",
      "917/917 [==============================] - 872s - loss: 0.0426 - acc: 0.9888 - val_loss: 0.0031 - val_acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcc9d996198>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine-tune the model\n",
    "watch_model.fit_generator(\n",
    "        multiclass_flow_train(train_generator, multiclasses_getter),\n",
    "        steps_per_epoch=nb_train_samples // batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data = multiclass_flow_test(test_generator, multiclasses_getter),\n",
    "        validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "watch_model.save('inception_v3_multiclass1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # fine-tune the model\n",
    "# watch_model.fit_generator(\n",
    "#         multiclass_flow_from_directory(train_generator, multiclasses_getter),\n",
    "#         steps_per_epoch=nb_train_samples // batch_size,\n",
    "#         epochs=epochs,\n",
    "#         validation_data = multiclass_flow_from_directory(test_generator, multiclasses_getter),\n",
    "#         validation_steps=nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_image(image_path):\n",
    "    \n",
    "    im = cv2.imread(image_path)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "    im = cv2.resize(im, (299, 299)).astype(np.float32)\n",
    "    im = im/255\n",
    "#     im[:,:,0] -= 103.939\n",
    "#     im[:,:,1] -= 116.779\n",
    "#     im[:,:,2] -= 123.68\n",
    "#    im = im.transpose((2,0,1))\n",
    "    im = np.expand_dims(im, axis=0)\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pic_path = 'all_pics/'\n",
    "f_list = os.listdir(pic_path)\n",
    "\n",
    "X_data = []\n",
    "for pic_name in f_list:\n",
    "    next_pic = prepare_image(pic_path + pic_name)\n",
    "    X_data.append(next_pic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(X_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
